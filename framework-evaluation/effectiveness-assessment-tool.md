# ICT Governance Framework Effectiveness Assessment Tool

## Document Information
- **Tool Name:** Framework Effectiveness Assessment Tool
- **Tool ID:** FEAT-001
- **Version:** 1.0.0
- **Created Date:** August 7, 2025
- **Owner:** ICT Governance Council
- **Framework:** CBA Consult IT Management Framework v3.2.0

## Purpose

This tool implements **Task 5: Evaluate Framework Effectiveness** from the CBA Consult IT Management Framework smart tasks. It provides a comprehensive methodology for measuring the impact of the governance framework on business outcomes and identifying areas for improvement.

## Assessment Framework Overview

The effectiveness assessment is based on a multi-dimensional evaluation model that measures:

1. **Strategic Alignment** - How well IT initiatives align with business objectives
2. **Operational Excellence** - Efficiency and effectiveness of IT operations
3. **Risk Management** - Effectiveness of risk identification and mitigation
4. **Value Delivery** - Business value generated from IT investments
5. **Compliance & Governance** - Adherence to policies and regulatory requirements
6. **Innovation Enablement** - Framework's ability to support innovation
7. **Stakeholder Satisfaction** - User and stakeholder satisfaction levels

## Assessment Methodology

### Phase 1: Data Collection (Weeks 1-2)

#### Quantitative Metrics Collection
- **Performance Metrics**: System availability, response times, incident resolution
- **Financial Metrics**: IT costs, ROI, budget variance, cost optimization
- **Compliance Metrics**: Policy adherence, audit findings, regulatory compliance
- **Operational Metrics**: Project delivery, change success rate, service quality

#### Qualitative Data Gathering
- **Stakeholder Interviews**: Executive leadership, IT staff, business users
- **Survey Deployment**: Governance effectiveness survey to all stakeholders
- **Focus Groups**: Targeted discussions with key user groups
- **Document Review**: Policies, procedures, incident reports, audit findings

### Phase 2: Analysis and Scoring (Weeks 3-4)

#### Scoring Methodology
Each dimension is scored on a scale of 1-5:
- **1 - Poor**: Significant deficiencies, major improvements needed
- **2 - Below Average**: Some deficiencies, improvements required
- **3 - Average**: Meets basic requirements, minor improvements needed
- **4 - Good**: Exceeds requirements, minor enhancements possible
- **5 - Excellent**: Best-in-class performance, minimal improvements needed

#### Weighted Scoring Model
| Dimension | Weight | Rationale |
|-----------|--------|-----------|
| Strategic Alignment | 20% | Critical for business value |
| Operational Excellence | 18% | Core IT service delivery |
| Risk Management | 16% | Essential for business continuity |
| Value Delivery | 15% | Demonstrates IT contribution |
| Compliance & Governance | 12% | Regulatory and policy adherence |
| Innovation Enablement | 10% | Future competitiveness |
| Stakeholder Satisfaction | 9% | User experience and adoption |

### Phase 3: Reporting and Recommendations (Week 5)

#### Assessment Report Structure
1. **Executive Summary**: Key findings and overall effectiveness score
2. **Detailed Analysis**: Dimension-by-dimension assessment
3. **Benchmarking**: Comparison with industry standards
4. **Gap Analysis**: Identification of improvement opportunities
5. **Recommendations**: Prioritized improvement initiatives
6. **Implementation Roadmap**: Timeline and resource requirements

## Assessment Dimensions and Metrics

### 1. Strategic Alignment (Weight: 20%)

#### Key Performance Indicators
- **IT-Business Alignment Score**: Percentage of IT initiatives aligned with business strategy
- **Strategic Project Success Rate**: Percentage of strategic projects delivered on time and budget
- **Business Stakeholder Satisfaction**: Survey score from business leaders
- **Technology Investment ROI**: Return on investment for major technology initiatives

#### Assessment Criteria
| Metric | Excellent (5) | Good (4) | Average (3) | Below Average (2) | Poor (1) |
|--------|---------------|----------|-------------|-------------------|----------|
| IT-Business Alignment | >95% | 85-95% | 70-84% | 55-69% | <55% |
| Strategic Project Success | >90% | 80-90% | 65-79% | 50-64% | <50% |
| Business Satisfaction | >4.5/5 | 4.0-4.5 | 3.5-3.9 | 3.0-3.4 | <3.0 |
| Technology ROI | >25% | 20-25% | 15-19% | 10-14% | <10% |

#### Data Sources
- Project portfolio management system
- Business stakeholder surveys
- Financial systems and budget reports
- Strategic planning documents

### 2. Operational Excellence (Weight: 18%)

#### Key Performance Indicators
- **System Availability**: Percentage uptime of critical systems
- **Incident Resolution Time**: Average time to resolve incidents
- **Change Success Rate**: Percentage of changes implemented without issues
- **Service Level Achievement**: Percentage of SLAs met or exceeded

#### Assessment Criteria
| Metric | Excellent (5) | Good (4) | Average (3) | Below Average (2) | Poor (1) |
|--------|---------------|----------|-------------|-------------------|----------|
| System Availability | >99.9% | 99.5-99.9% | 99.0-99.4% | 98.0-98.9% | <98.0% |
| Incident Resolution | <2 hours | 2-4 hours | 4-8 hours | 8-24 hours | >24 hours |
| Change Success Rate | >95% | 90-95% | 80-89% | 70-79% | <70% |
| SLA Achievement | >98% | 95-98% | 90-94% | 85-89% | <85% |

#### Data Sources
- IT service management tools
- Monitoring and alerting systems
- Change management records
- Service level reports

### 3. Risk Management (Weight: 16%)

#### Key Performance Indicators
- **Risk Assessment Coverage**: Percentage of systems with current risk assessments
- **Security Incident Frequency**: Number of security incidents per month
- **Compliance Audit Results**: Percentage of audit findings resolved
- **Business Continuity Readiness**: Percentage of critical systems with DR plans

#### Assessment Criteria
| Metric | Excellent (5) | Good (4) | Average (3) | Below Average (2) | Poor (1) |
|--------|---------------|----------|-------------|-------------------|----------|
| Risk Assessment Coverage | >95% | 85-95% | 70-84% | 55-69% | <55% |
| Security Incidents | 0-1/month | 2-3/month | 4-6/month | 7-10/month | >10/month |
| Audit Findings Resolution | >95% | 85-95% | 70-84% | 55-69% | <55% |
| DR Plan Coverage | >90% | 80-90% | 65-79% | 50-64% | <50% |

#### Data Sources
- Risk management systems
- Security incident logs
- Audit reports and findings
- Business continuity documentation

### 4. Value Delivery (Weight: 15%)

#### Key Performance Indicators
- **IT Cost as % of Revenue**: IT spending relative to organizational revenue
- **Cost Optimization Achievements**: Percentage cost reduction from optimization initiatives
- **User Productivity Improvement**: Measured improvement in user productivity
- **Innovation Project Success**: Percentage of innovation projects delivering value

#### Assessment Criteria
| Metric | Excellent (5) | Good (4) | Average (3) | Below Average (2) | Poor (1) |
|--------|---------------|----------|-------------|-------------------|----------|
| IT Cost Efficiency | <3% revenue | 3-4% | 4-5% | 5-6% | >6% |
| Cost Optimization | >15% reduction | 10-15% | 5-9% | 1-4% | <1% |
| Productivity Improvement | >20% | 15-20% | 10-14% | 5-9% | <5% |
| Innovation Success | >80% | 70-80% | 60-69% | 50-59% | <50% |

#### Data Sources
- Financial systems and budgets
- Cost optimization tracking
- Productivity measurement tools
- Innovation project portfolios

### 5. Compliance & Governance (Weight: 12%)

#### Key Performance Indicators
- **Policy Compliance Rate**: Percentage adherence to governance policies
- **Regulatory Compliance Score**: Compliance with applicable regulations
- **Governance Process Maturity**: Maturity level of governance processes
- **Documentation Currency**: Percentage of policies and procedures up to date

#### Assessment Criteria
| Metric | Excellent (5) | Good (4) | Average (3) | Below Average (2) | Poor (1) |
|--------|---------------|----------|-------------|-------------------|----------|
| Policy Compliance | >95% | 90-95% | 80-89% | 70-79% | <70% |
| Regulatory Compliance | 100% | 98-99% | 95-97% | 90-94% | <90% |
| Process Maturity | Level 5 | Level 4 | Level 3 | Level 2 | Level 1 |
| Documentation Currency | >95% | 85-95% | 70-84% | 55-69% | <55% |

#### Data Sources
- Compliance monitoring systems
- Regulatory audit reports
- Process maturity assessments
- Document management systems

### 6. Innovation Enablement (Weight: 10%)

#### Key Performance Indicators
- **Technology Modernization Rate**: Percentage of systems on current technology
- **Innovation Investment**: Percentage of IT budget allocated to innovation
- **Time to Market**: Average time to deploy new capabilities
- **Technology Adoption Rate**: Speed of adopting new technologies

#### Assessment Criteria
| Metric | Excellent (5) | Good (4) | Average (3) | Below Average (2) | Poor (1) |
|--------|---------------|----------|-------------|-------------------|----------|
| Technology Modernization | >80% | 70-80% | 60-69% | 50-59% | <50% |
| Innovation Investment | >15% budget | 12-15% | 8-11% | 5-7% | <5% |
| Time to Market | <30 days | 30-60 days | 60-90 days | 90-120 days | >120 days |
| Technology Adoption | <6 months | 6-12 months | 12-18 months | 18-24 months | >24 months |

#### Data Sources
- Technology inventory systems
- Budget and financial reports
- Project delivery metrics
- Technology adoption tracking

### 7. Stakeholder Satisfaction (Weight: 9%)

#### Key Performance Indicators
- **User Satisfaction Score**: Overall satisfaction with IT services
- **Executive Satisfaction**: Leadership satisfaction with IT governance
- **IT Staff Satisfaction**: IT team satisfaction with governance processes
- **Service Desk Satisfaction**: User satisfaction with support services

#### Assessment Criteria
| Metric | Excellent (5) | Good (4) | Average (3) | Below Average (2) | Poor (1) |
|--------|---------------|----------|-------------|-------------------|----------|
| User Satisfaction | >4.5/5 | 4.0-4.5 | 3.5-3.9 | 3.0-3.4 | <3.0 |
| Executive Satisfaction | >4.5/5 | 4.0-4.5 | 3.5-3.9 | 3.0-3.4 | <3.0 |
| IT Staff Satisfaction | >4.0/5 | 3.5-4.0 | 3.0-3.4 | 2.5-2.9 | <2.5 |
| Service Desk Satisfaction | >4.0/5 | 3.5-4.0 | 3.0-3.4 | 2.5-2.9 | <2.5 |

#### Data Sources
- User satisfaction surveys
- Executive feedback sessions
- IT staff engagement surveys
- Service desk feedback systems

## Assessment Tools and Templates

### 1. Stakeholder Survey Template

#### Executive Leadership Survey
**Instructions**: Please rate each statement on a scale of 1-5 (1=Strongly Disagree, 5=Strongly Agree)

1. IT initiatives are well-aligned with our business strategy
2. IT governance processes support business decision-making
3. IT investments deliver measurable business value
4. IT risks are effectively identified and managed
5. IT services meet our operational requirements
6. The IT organization is responsive to business needs
7. IT governance enables rather than hinders innovation
8. Overall, I am satisfied with IT governance effectiveness

#### Business User Survey
**Instructions**: Please rate each statement on a scale of 1-5 (1=Strongly Disagree, 5=Strongly Agree)

1. IT systems are reliable and available when needed
2. IT support is responsive and helpful
3. New IT capabilities are delivered in a timely manner
4. IT systems help me be more productive in my work
5. IT security measures are appropriate and not overly burdensome
6. I receive adequate training on new IT systems
7. IT governance policies are clear and reasonable
8. Overall, I am satisfied with IT services

#### IT Staff Survey
**Instructions**: Please rate each statement on a scale of 1-5 (1=Strongly Disagree, 5=Strongly Agree)

1. Governance processes are clearly defined and documented
2. Governance processes help rather than hinder my work
3. I have the tools and resources needed to follow governance processes
4. Governance requirements are reasonable and achievable
5. There is adequate training on governance processes
6. Governance processes support quality service delivery
7. Management supports governance process compliance
8. Overall, governance processes are effective

### 2. Data Collection Templates

#### Quantitative Metrics Collection Template
```
Assessment Period: [Start Date] to [End Date]
Data Collection Date: [Date]
Collected By: [Name and Role]

Strategic Alignment Metrics:
- IT-Business Alignment Score: ____%
- Strategic Project Success Rate: ____%
- Business Stakeholder Satisfaction: ____/5
- Technology Investment ROI: ____%

Operational Excellence Metrics:
- System Availability: ____%
- Average Incident Resolution Time: ____ hours
- Change Success Rate: ____%
- SLA Achievement Rate: ____%

[Continue for all dimensions...]

Data Sources Used:
- [ ] Project management systems
- [ ] Monitoring tools
- [ ] Financial systems
- [ ] Survey results
- [ ] Audit reports
- [ ] Other: ____________

Data Quality Assessment:
- Completeness: ____%
- Accuracy: ____%
- Timeliness: ____%
- Reliability: ____%

Notes and Comments:
[Free text area for additional observations]
```

### 3. Assessment Report Template

#### Executive Summary Template
```
ICT Governance Framework Effectiveness Assessment
Executive Summary

Assessment Period: [Date Range]
Overall Effectiveness Score: ____/5.0

Key Findings:
• [Top 3-5 key findings]

Strengths:
• [Top 3 strengths identified]

Areas for Improvement:
• [Top 3 improvement areas]

Recommendations:
• [Top 3 priority recommendations]

Next Steps:
• [Immediate actions required]
```

## Implementation Guidelines

### Assessment Frequency
- **Comprehensive Assessment**: Annually
- **Quarterly Reviews**: Key metrics monitoring
- **Monthly Dashboards**: Operational metrics tracking
- **Continuous Monitoring**: Critical performance indicators

### Roles and Responsibilities

#### Assessment Team
- **Assessment Lead**: ICT Governance Council member
- **Data Analysts**: Collect and analyze quantitative metrics
- **Survey Coordinators**: Manage stakeholder surveys and interviews
- **Subject Matter Experts**: Provide domain-specific insights

#### Stakeholder Involvement
- **Executive Sponsors**: Provide strategic context and priorities
- **Business Leaders**: Participate in interviews and surveys
- **IT Staff**: Provide operational data and insights
- **End Users**: Complete satisfaction surveys

### Success Factors
1. **Executive Support**: Strong leadership commitment to assessment process
2. **Data Quality**: Accurate and timely data collection
3. **Stakeholder Engagement**: Active participation from all stakeholder groups
4. **Action Orientation**: Commitment to act on assessment findings
5. **Continuous Improvement**: Regular refinement of assessment methodology

## Benchmarking and Industry Comparison

### Industry Benchmarks
- **Strategic Alignment**: Industry average 3.2/5.0
- **Operational Excellence**: Industry average 3.5/5.0
- **Risk Management**: Industry average 3.1/5.0
- **Value Delivery**: Industry average 3.0/5.0
- **Compliance & Governance**: Industry average 3.4/5.0
- **Innovation Enablement**: Industry average 2.8/5.0
- **Stakeholder Satisfaction**: Industry average 3.3/5.0

### Maturity Level Mapping
- **Level 1 (Initial)**: Score 1.0-1.9 - Ad hoc processes, reactive approach
- **Level 2 (Managed)**: Score 2.0-2.9 - Basic processes in place, some documentation
- **Level 3 (Defined)**: Score 3.0-3.9 - Standardized processes, proactive management
- **Level 4 (Quantitatively Managed)**: Score 4.0-4.9 - Measured processes, continuous improvement
- **Level 5 (Optimizing)**: Score 5.0 - Optimized processes, innovation focus

## Continuous Improvement Process

### Assessment Results Analysis
1. **Trend Analysis**: Compare results over time to identify improvement trends
2. **Root Cause Analysis**: Investigate underlying causes of performance gaps
3. **Best Practice Identification**: Identify and document successful practices
4. **Benchmarking**: Compare performance against industry standards

### Improvement Planning
1. **Priority Setting**: Rank improvement opportunities by impact and effort
2. **Initiative Definition**: Define specific improvement initiatives
3. **Resource Allocation**: Assign resources and budgets to initiatives
4. **Timeline Development**: Create realistic implementation timelines

### Implementation Monitoring
1. **Progress Tracking**: Monitor implementation progress against plans
2. **Milestone Reviews**: Conduct regular milestone review meetings
3. **Issue Resolution**: Address implementation challenges promptly
4. **Success Measurement**: Measure and report on improvement results

## Related Documents

- [ICT Governance Framework](../ICT-Governance-Framework.md)
- [Target Governance Framework](../Target-Governance-Framework.md)
- [Governance Framework Assessment Report](../governance-framework-assessment-report.md)
- [Governance Gaps and Recommendations](../governance-gaps-and-recommendations.md)

## Revision History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0.0 | 2025-08-07 | ICT Governance Team | Initial tool creation |

---

*This effectiveness assessment tool is part of the CBA Consult IT Management Framework and implements Task 5 of the smart tasks framework. It should be customized to meet specific organizational requirements and measurement needs.*